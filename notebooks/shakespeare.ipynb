{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = !cd shakespeare_data/train; ls\n",
    "test_files = !cd shakespeare_data/test; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_data_niid_0_keep_0_test_9.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespeare_data/train/all_data_niid_0_keep_0_train_9.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('shakespeare_data/test/all_data_niid_0_keep_0_test_9.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, num_samples_train, user_data_train, hierarchies = (\n",
    "    train_data[x] for x in ['users', 'num_samples', 'user_data', 'hierarchies'])\n",
    "_, num_samples_test, user_data_test, _ = (\n",
    "    test_data[x] for x in ['users', 'num_samples', 'user_data', 'hierarchies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "user_info = pd.DataFrame({\n",
    "    'play' : hierarchies, \n",
    "    'user' : users, \n",
    "    'num_samples_train' : num_samples_train, \n",
    "    'num_samples_test': num_samples_test})\n",
    "\n",
    "user_info['user_id'] = user_info['user'].astype('category').cat.codes\n",
    "user_info['play_id'] = user_info['play'].astype('category').cat.codes\n",
    "\n",
    "user_info = user_info.set_index('user')\n",
    "\n",
    "#user_info.set_index(['play_id','user_id']).sort_index()\n",
    "\n",
    "#user_info.apply(lambda row: re.sub(re.sub(' ', '_', row['play']), '', row['user']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>num_samples_train</th>\n",
       "      <th>num_samples_test</th>\n",
       "      <th>user_id</th>\n",
       "      <th>play_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_BERTRAM</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>9484</td>\n",
       "      <td>1054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_CLOWN</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>7551</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_COUNTESS</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>10348</td>\n",
       "      <td>1150</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_DIANA</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>4616</td>\n",
       "      <td>513</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_DUKE</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>560</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_FIRST_GENTLEMAN</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>309</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_FIRST_LORD</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>3357</td>\n",
       "      <td>373</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_FIRST_SOLDIER</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>2902</td>\n",
       "      <td>323</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_GENTLEMAN</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>559</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_HELENA</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>16825</td>\n",
       "      <td>1870</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              play  \\\n",
       "user                                                                 \n",
       "ALLS_WELL_THAT_ENDS_WELL_BERTRAM          ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_CLOWN            ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_COUNTESS         ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_DIANA            ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_DUKE             ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_GENTLEMAN  ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_LORD       ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_SOLDIER    ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_GENTLEMAN        ALLS WELL THAT ENDS WELL   \n",
       "ALLS_WELL_THAT_ENDS_WELL_HELENA           ALLS WELL THAT ENDS WELL   \n",
       "\n",
       "                                          num_samples_train  num_samples_test  \\\n",
       "user                                                                            \n",
       "ALLS_WELL_THAT_ENDS_WELL_BERTRAM                       9484              1054   \n",
       "ALLS_WELL_THAT_ENDS_WELL_CLOWN                         7551               840   \n",
       "ALLS_WELL_THAT_ENDS_WELL_COUNTESS                     10348              1150   \n",
       "ALLS_WELL_THAT_ENDS_WELL_DIANA                         4616               513   \n",
       "ALLS_WELL_THAT_ENDS_WELL_DUKE                           560                63   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_GENTLEMAN                309                35   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_LORD                    3357               373   \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_SOLDIER                 2902               323   \n",
       "ALLS_WELL_THAT_ENDS_WELL_GENTLEMAN                      559                63   \n",
       "ALLS_WELL_THAT_ENDS_WELL_HELENA                       16825              1870   \n",
       "\n",
       "                                          user_id  play_id  \n",
       "user                                                        \n",
       "ALLS_WELL_THAT_ENDS_WELL_BERTRAM                0        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_CLOWN                  1        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_COUNTESS               2        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_DIANA                  3        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_DUKE                   4        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_GENTLEMAN        5        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_LORD             6        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_FIRST_SOLDIER          7        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_GENTLEMAN              8        1  \n",
       "ALLS_WELL_THAT_ENDS_WELL_HELENA                 9        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KING RICHARD III                            52\n",
       "THE SECOND PART OF KING HENRY THE SIXTH     52\n",
       "THE TRAGEDY OF ANTONY AND CLEOPATRA         50\n",
       "THE LIFE OF TIMON OF ATHENS                 48\n",
       "THE TRAGEDY OF CORIOLANUS                   47\n",
       "THE FIRST PART OF HENRY THE SIXTH           45\n",
       "SECOND PART OF KING HENRY IV                44\n",
       "THE LIFE OF KING HENRY THE FIFTH            42\n",
       "KING HENRY THE EIGHTH                       42\n",
       "THE THIRD PART OF KING HENRY THE SIXTH      40\n",
       "THE TRAGEDY OF JULIUS CAESAR                40\n",
       "THE TRAGEDY OF MACBETH                      38\n",
       "CYMBELINE                                   36\n",
       "KING RICHARD THE SECOND                     34\n",
       "THE TRAGEDY OF ROMEO AND JULIET             32\n",
       "THE WINTER'S TALE                           32\n",
       "THE FIRST PART OF KING HENRY THE FOURTH     30\n",
       "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK    29\n",
       "A MIDSUMMER NIGHT'S DREAM                   28\n",
       "THE TAMING OF THE SHREW                     28\n",
       "THE HISTORY OF TROILUS AND CRESSIDA         26\n",
       "THE TRAGEDY OF TITUS ANDRONICUS             26\n",
       "KING JOHN                                   25\n",
       "AS YOU LIKE IT                              25\n",
       "THE TRAGEDY OF OTHELLO, MOOR OF VENICE      23\n",
       "MEASURE FOR MEASURE                         22\n",
       "THE MERRY WIVES OF WINDSOR                  22\n",
       "THE MERCHANT OF VENICE                      21\n",
       "THE COMEDY OF ERRORS                        21\n",
       "THE TRAGEDY OF KING LEAR                    21\n",
       "TWELFTH NIGHT; OR, WHAT YOU WILL            19\n",
       "ALLS WELL THAT ENDS WELL                    19\n",
       "THE TEMPEST                                 18\n",
       "MUCH ADO ABOUT NOTHING                      18\n",
       "LOVE'S LABOUR'S LOST                        18\n",
       "THE TWO GENTLEMEN OF VERONA                 16\n",
       "Name: play, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 36 different plays\n",
    "# 1000 different speakers\n",
    "user_info['play'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data, batch_size):\n",
    "    '''\n",
    "    data is a dict := {'x': [list], 'y': [list]}\n",
    "    returns x, y, which are both lists of size-batch_size lists\n",
    "    '''\n",
    "    raw_x = data['x']\n",
    "    raw_y = data['y']        \n",
    "    batched_x = []\n",
    "    batched_y = []\n",
    "    for i in range(0, len(raw_x), batch_size):\n",
    "        batched_x.append(raw_x[i:i+batch_size])\n",
    "        batched_y.append(raw_y[i:i+batch_size])\n",
    "    return batched_x, batched_y\n",
    "\n",
    "\n",
    "def read_data(train_data_dir, test_data_dir):\n",
    "    '''parses data in given train and test data directories\n",
    "\n",
    "    assumes:\n",
    "    - the data in the input directories are .json files with \n",
    "        keys 'users' and 'user_data'\n",
    "    - the set of train set users is the same as the set of test set users\n",
    "    \n",
    "    Return:\n",
    "        clients: list of client ids\n",
    "        groups: list of group ids; empty list if none found\n",
    "        train_data: dictionary of train data\n",
    "        test_data: dictionary of test data\n",
    "    '''\n",
    "    clients = []\n",
    "    groups = []\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    train_files = os.listdir(train_data_dir)\n",
    "    train_files = [f for f in train_files if f.endswith('.json')]\n",
    "    for f in train_files:\n",
    "        file_path = os.path.join(train_data_dir,f)\n",
    "        with open(file_path, 'r') as inf:\n",
    "            cdata = json.load(inf)\n",
    "        clients.extend(cdata['users'])\n",
    "        if 'hierarchies' in cdata:\n",
    "            groups.extend(cdata['hierarchies'])\n",
    "        train_data.update(cdata['user_data'])\n",
    "\n",
    "    test_files = os.listdir(test_data_dir)\n",
    "    test_files = [f for f in test_files if f.endswith('.json')]\n",
    "    for f in test_files:\n",
    "        file_path = os.path.join(test_data_dir, f)\n",
    "        with open(file_path, 'r') as inf:\n",
    "            cdata = json.load(inf)\n",
    "        test_data.update(cdata['user_data'])\n",
    "\n",
    "    clients = list(train_data.keys())\n",
    "\n",
    "    return clients, groups, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "#from tensorflow.contrib import rnn\n",
    "\n",
    "#from model import Model\n",
    "#from utils.language_utils import letter_to_vec, word_to_indices\n",
    "\n",
    "\"\"\"Utils for language models.\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# utils for shakespeare dataset\n",
    "\n",
    "ALL_LETTERS = \" ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "NUM_LETTERS = len(ALL_LETTERS)\n",
    "\n",
    "\n",
    "def _one_hot(index, size):\n",
    "    \"\"\"Returns one-hot vector with given size and value 1 at given index.\"\"\"\n",
    "    vec = [0 for _ in range(size)]\n",
    "    vec[int(index)] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "def letter_to_vec(letter):\n",
    "    \"\"\"Returns one-hot representation of given letter.\"\"\"\n",
    "    index = max(0,ALL_LETTERS.find(letter)) # treating ' ' as unknown character\n",
    "    return _one_hot(index, NUM_LETTERS)\n",
    "\n",
    "def letter_to_index(letter):\n",
    "    \"\"\"Returns one-hot representation of given letter.\"\"\"\n",
    "    index = max(0,ALL_LETTERS.find(letter)) # treating ' ' as unknown character\n",
    "    return index\n",
    "\n",
    "\n",
    "def word_to_indices(word):\n",
    "    '''returns a list of character indices\n",
    "\n",
    "    Args:\n",
    "        word: string\n",
    "    \n",
    "    Return:\n",
    "        indices: int list with length len(word)\n",
    "    '''\n",
    "    indices = []\n",
    "    for c in word:\n",
    "        indices.append(max(0, ALL_LETTERS.find(c))) # added max to account for -1\n",
    "    return indices\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# utils for sent140 dataset\n",
    "\n",
    "\n",
    "def split_line(line):\n",
    "    \"\"\"Split given line/phrase into list of words\n",
    "\n",
    "    Args:\n",
    "        line: string representing phrase to be split\n",
    "    \n",
    "    Return:\n",
    "        list of strings, with each string representing a word\n",
    "    \"\"\"\n",
    "    return re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
    "\n",
    "\n",
    "def _word_to_index(word, indd):\n",
    "    \"\"\"Returns index of given word based on given lookup dictionary\n",
    "\n",
    "    returns the length of the lookup dictionary if word not found\n",
    "\n",
    "    Args:\n",
    "        word: string\n",
    "        indd: dictionary with string words as keys and int indices as values\n",
    "    \"\"\"\n",
    "    if word in indd:\n",
    "        return indd[word]\n",
    "    else:\n",
    "        return len(indd)\n",
    "\n",
    "\n",
    "def line_to_indices(line, indd, max_words=25):\n",
    "    \"\"\"Converts given phrase into list of word indices\n",
    "    \n",
    "    if the phrase has more than max_words words, returns a list containing\n",
    "    indices of the first max_words words\n",
    "    if the phrase has less than max_words words, repeatedly appends integer \n",
    "    representing unknown index to returned list until the list's length is \n",
    "    max_words\n",
    "\n",
    "    Args:\n",
    "        line: string representing phrase/sequence of words\n",
    "        indd: dictionary with string words as keys and int indices as values\n",
    "        max_words: maximum number of word indices in returned list\n",
    "\n",
    "    Return:\n",
    "        indl: list of word indices, one index for each word in phrase\n",
    "    \"\"\"\n",
    "    line_list = split_line(line) # split phrase in words\n",
    "    indl = []\n",
    "    for word in line_list:\n",
    "        cind = _word_to_index(word, indd)\n",
    "        indl.append(cind)\n",
    "        if (len(indl) == max_words):\n",
    "            break\n",
    "    for i in range(max_words - len(indl)):\n",
    "        indl.append(len(indd))\n",
    "    return indl\n",
    "\n",
    "\n",
    "def bag_of_words(line, vocab):\n",
    "    \"\"\"Returns bag of words representation of given phrase using given vocab.\n",
    "\n",
    "    Args:\n",
    "        line: string representing phrase to be parsed\n",
    "        vocab: dictionary with words as keys and indices as values\n",
    "\n",
    "    Return:\n",
    "        integer list\n",
    "    \"\"\"\n",
    "    bag = [0]*len(vocab)\n",
    "    words = split_line(line)\n",
    "    for w in words:\n",
    "        if w in vocab:\n",
    "            bag[vocab[w]] += 1\n",
    "    return bag\n",
    "\n",
    "\n",
    "def get_word_emb_arr(path):\n",
    "    with open(path, 'r') as inf:\n",
    "        embs = json.load(inf)\n",
    "    vocab = embs['vocab']\n",
    "    word_emb_arr = np.array(embs['emba'])\n",
    "    indd = {}\n",
    "    for i in range(len(vocab)):\n",
    "        indd[vocab[i]] = i\n",
    "    vocab = {w: i for i, w in enumerate(embs['vocab'])}\n",
    "    return word_emb_arr, indd, vocab\n",
    "\n",
    "\n",
    "def val_to_vec(size, val):\n",
    "    \"\"\"Converts target into one-hot.\n",
    "\n",
    "    Args:\n",
    "        size: Size of vector.\n",
    "        val: Integer in range [0, size].\n",
    "    Returns:\n",
    "         vec: one-hot vector with a 1 in the val element.\n",
    "    \"\"\"\n",
    "    assert 0 <= val < size\n",
    "    vec = [0 for _ in range(size)]\n",
    "    vec[int(val)] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel():\n",
    "    def __init__(self, lr, seq_len, num_classes, n_hidden):\n",
    "        self.lr = lr\n",
    "        self.seq_len = seq_len\n",
    "        self.num_classes = num_classes\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "\n",
    "    def create_model(self):\n",
    "        features = tf.placeholder(tf.int32, [None, self.seq_len])\n",
    "        embedding = tf.get_variable(\"embedding\", [self.num_classes, 8])\n",
    "        x = tf.nn.embedding_lookup(embedding, features)\n",
    "        labels = tf.placeholder(tf.int32, [None, self.num_classes])\n",
    "        \n",
    "        stacked_lstm = rnn.MultiRNNCell(\n",
    "            [rnn.BasicLSTMCell(self.n_hidden) for _ in range(2)])\n",
    "        outputs, _ = tf.nn.dynamic_rnn(stacked_lstm, x, dtype=tf.float32)\n",
    "        pred = tf.layers.dense(inputs=outputs[:,-1,:], units=self.num_classes)\n",
    "        \n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=labels))\n",
    "        train_op = self.optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "\n",
    "        correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(labels, 1))\n",
    "        eval_metric_ops = tf.count_nonzero(correct_pred)\n",
    "\n",
    "        return features, labels, train_op, eval_metric_ops\n",
    "\n",
    "    def process_x(self, raw_x_batch):\n",
    "        x_batch = [word_to_indices(word) for word in raw_x_batch]\n",
    "        x_batch = np.array(x_batch)\n",
    "        return x_batch\n",
    "\n",
    "    def process_y(self, raw_y_batch):\n",
    "        y_batch = [letter_to_vec(c) for c in raw_y_batch]\n",
    "        return y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ClientModel(0.001, 80,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('shakespeare_data/train', 'shakespeare_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e34e3c735e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KING_RICHARD_III_SON'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data[2]['KING_RICHARD_III_SON']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antonio, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, ',\n",
       " 'ntonio, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I',\n",
       " 'tonio, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I ',\n",
       " 'onio, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I p',\n",
       " 'nio, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pr',\n",
       " 'io, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pra',\n",
       " 'o, I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray',\n",
       " ', I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray ',\n",
       " ' I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray y',\n",
       " 'I arrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray yo',\n",
       " 'rrest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray you g',\n",
       " 'rest thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray you go',\n",
       " 'est thee at the suit Of Count Orsino. Come, sir, away. Come, sir, I pray you go.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER']['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', ' ', 'p', 'r', 'a', 'y', ' ', 'y', 'o', 'u', 'o', '.', ' ']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER']['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_data_train['THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_vec(data):\n",
    "    return np.array(list(map(\n",
    "        lambda sent: np.array(list(map(letter_to_vec, sent))), data)))\n",
    "\n",
    "def data_to_index(data):\n",
    "    return np.array(list(map(\n",
    "        lambda sent: np.array(list(map(letter_to_index, sent))), data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>num_samples_train</th>\n",
       "      <th>num_samples_test</th>\n",
       "      <th>user_id</th>\n",
       "      <th>play_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER</th>\n",
       "      <td>TWELFTH NIGHT; OR, WHAT YOU WILL</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1124</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
       "      <td>334</td>\n",
       "      <td>38</td>\n",
       "      <td>819</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE_FIRST_PART_OF_HENRY_THE_SIXTH_COUNTESS</th>\n",
       "      <td>THE FIRST PART OF HENRY THE SIXTH</td>\n",
       "      <td>1736</td>\n",
       "      <td>193</td>\n",
       "      <td>393</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE_TRAGEDY_OF_JULIUS_CAESAR_ARTEMIDORUS</th>\n",
       "      <td>THE TRAGEDY OF JULIUS CAESAR</td>\n",
       "      <td>639</td>\n",
       "      <td>72</td>\n",
       "      <td>884</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE_SECOND_PART_OF_KING_HENRY_THE_SIXTH_WARWICK</th>\n",
       "      <td>THE SECOND PART OF KING HENRY THE SIXTH</td>\n",
       "      <td>5184</td>\n",
       "      <td>576</td>\n",
       "      <td>664</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    play  \\\n",
       "user                                                                                       \n",
       "TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER         TWELFTH NIGHT; OR, WHAT YOU WILL   \n",
       "THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD                           THE TRAGEDY OF CORIOLANUS   \n",
       "THE_FIRST_PART_OF_HENRY_THE_SIXTH_COUNTESS             THE FIRST PART OF HENRY THE SIXTH   \n",
       "THE_TRAGEDY_OF_JULIUS_CAESAR_ARTEMIDORUS                    THE TRAGEDY OF JULIUS CAESAR   \n",
       "THE_SECOND_PART_OF_KING_HENRY_THE_SIXTH_WARWICK  THE SECOND PART OF KING HENRY THE SIXTH   \n",
       "\n",
       "                                                 num_samples_train  \\\n",
       "user                                                                 \n",
       "TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER                 13   \n",
       "THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD                           334   \n",
       "THE_FIRST_PART_OF_HENRY_THE_SIXTH_COUNTESS                    1736   \n",
       "THE_TRAGEDY_OF_JULIUS_CAESAR_ARTEMIDORUS                       639   \n",
       "THE_SECOND_PART_OF_KING_HENRY_THE_SIXTH_WARWICK               5184   \n",
       "\n",
       "                                                 num_samples_test  user_id  \\\n",
       "user                                                                         \n",
       "TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER                 2     1124   \n",
       "THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD                           38      819   \n",
       "THE_FIRST_PART_OF_HENRY_THE_SIXTH_COUNTESS                    193      393   \n",
       "THE_TRAGEDY_OF_JULIUS_CAESAR_ARTEMIDORUS                       72      884   \n",
       "THE_SECOND_PART_OF_KING_HENRY_THE_SIXTH_WARWICK               576      664   \n",
       "\n",
       "                                                 play_id  \n",
       "user                                                      \n",
       "TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER       35  \n",
       "THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD                  25  \n",
       "THE_FIRST_PART_OF_HENRY_THE_SIXTH_COUNTESS            13  \n",
       "THE_TRAGEDY_OF_JULIUS_CAESAR_ARTEMIDORUS              27  \n",
       "THE_SECOND_PART_OF_KING_HENRY_THE_SIXTH_WARWICK       20  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play                 TWELFTH NIGHT; OR, WHAT YOU WILL\n",
       "num_samples_train                                  13\n",
       "num_samples_test                                    2\n",
       "user_id                                          1124\n",
       "play_id                                            35\n",
       "Name: TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.loc['TWELFTH_NIGHT__OR__WHAT_YOU_WILL_SECOND_OFFICER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d0261c8e826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user_info' is not defined"
     ]
    }
   ],
   "source": [
    "user_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = []\n",
    "users_test = []\n",
    "plays_train = []\n",
    "plays_test = []\n",
    "x_data_train = []\n",
    "x_data_test = []\n",
    "y_data_train = []\n",
    "y_data_test = []\n",
    "for i in range(100):\n",
    "    user = data[0][i]\n",
    "    play = data[1][i]\n",
    "    train_data = data[2][user]\n",
    "    test_data = data[3][user]\n",
    "    \n",
    "    play, num_samples_train, num_samples_test, user_id, play_id = (\n",
    "        user_info.loc[user].values)\n",
    "    \n",
    "    users_train.append(np.array([user_id]*num_samples_train))\n",
    "    users_test.append(np.array([user_id]*num_samples_test))\n",
    "    plays_train.append(np.array([play_id]*num_samples_train))\n",
    "    plays_test.append(np.array([play_id]*num_samples_test))\n",
    "    x_data_train.append(data_to_index(train_data['x']))\n",
    "    x_data_test.append(data_to_index(test_data['x']))\n",
    "    y_data_train.append(data_to_index(train_data['y']))\n",
    "    y_data_test.append(data_to_index(test_data['y']))\n",
    "    \n",
    "users_train = np.concatenate(users_train)\n",
    "users_test = np.concatenate(users_test)\n",
    "plays_train = np.concatenate(plays_train)\n",
    "plays_test = np.concatenate(plays_test)\n",
    "x_data_train = np.concatenate(x_data_train)\n",
    "x_data_test = np.concatenate(x_data_test)\n",
    "y_data_train = np.concatenate(y_data_train)\n",
    "y_data_test = np.concatenate(y_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shakespeare_data/small_dataset/x_train.npy', x_data_train)\n",
    "np.save('shakespeare_data/small_dataset/y_train.npy', y_data_train)\n",
    "np.save('shakespeare_data/small_dataset/x_test.npy', x_data_test)\n",
    "np.save('shakespeare_data/small_dataset/y_test.npy', y_data_test)\n",
    "np.save('shakespeare_data/small_dataset/gid_train.npy', users_train)\n",
    "np.save('shakespeare_data/small_dataset/gid_test.npy', users_test )\n",
    "np.save('shakespeare_data/small_dataset/gid2_train.npy', plays_train)\n",
    "np.save('shakespeare_data/small_dataset/gid2_test.npy', plays_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.to_pickle('shakespeare_data/user_info.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = np.load('shakespeare_data/small_dataset/x_train.npy')\n",
    "users_test = np.load('shakespeare_data/small_dataset/y_train.npy')\n",
    "plays_train = np.load('shakespeare_data/small_dataset/x_test.npy')\n",
    "plays_test = np.load('shakespeare_data/small_dataset/y_test.npy')\n",
    "x_data_train = np.load('shakespeare_data/small_dataset/gid_train.npy')\n",
    "x_data_test = np.load('shakespeare_data/small_dataset/gid_test.npy')\n",
    "y_data_train = np.load('shakespeare_data/small_dataset/gid2_train.npy')\n",
    "y_data_test = np.load('shakespeare_data/small_dataset/gid2_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data = np.squeeze(data_to_vec(user_data_train['THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD']['y']))\n",
    "#x_data = data_to_vec(user_data_train['THE_TRAGEDY_OF_CORIOLANUS_FIRST_LORD']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41097, 80)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((334, 80, 53), (334, 53))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Input(batch_size=100, shape=(80,53), sparse=True),\n",
    "    Embedding(53, 128, input_length=80),\n",
    "    LSTM(256, return_sequences=True),\n",
    "    LSTM(256),\n",
    "    #Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(53, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Input(batch_size=100, shape=(80,53), sparse=True),\n",
    "    Embedding(53, 256, input_length=80),\n",
    "    Conv1D(256, 5, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(512, 5,  activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(1024, 3,  activation='relu'),\n",
    "    #MaxPooling1D(3),\n",
    "    #Conv1D(1024, 3,  activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(53)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4),\n",
    "    metrics=['acc'],\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 80, 128)           6784      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 80, 256)           394240    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 53)                13621     \n",
      "=================================================================\n",
      "Total params: 1,005,749\n",
      "Trainable params: 1,005,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 369430 samples\n",
      "184500/369430 [=============>................] - ETA: 34:39 - loss: 2.7366 - acc: 0.2654"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-598-bca08b3b37b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_data_train, y_data_train, batch_size=500, epochs=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_data_test, y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "      <th>num_samples_train</th>\n",
       "      <th>num_samples_test</th>\n",
       "      <th>user_id</th>\n",
       "      <th>play_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLS_WELL_THAT_ENDS_WELL_BERTRAM</th>\n",
       "      <td>ALLS WELL THAT ENDS WELL</td>\n",
       "      <td>9484</td>\n",
       "      <td>1054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      play  num_samples_train  \\\n",
       "user                                                                            \n",
       "ALLS_WELL_THAT_ENDS_WELL_BERTRAM  ALLS WELL THAT ENDS WELL               9484   \n",
       "\n",
       "                                  num_samples_test  user_id  play_id  \n",
       "user                                                                  \n",
       "ALLS_WELL_THAT_ENDS_WELL_BERTRAM              1054        0        1  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info[user_info['user_id']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" weep o'er my father's death anew; but I must attend his Majesty's command, to w\""
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['ALLS_WELL_THAT_ENDS_WELL_BERTRAM']['x'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\", madam, weep o'er my father's death anew; but I must attend his Majesty's comma\""
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]['ALLS_WELL_THAT_ENDS_WELL_BERTRAM']['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Antonio  I arrest thee at the suit Of Count Orsino  Come  sir  away  Come  sir  '"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(map(get_letter, x_data_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_letter = lambda x: ALL_LETTERS[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
