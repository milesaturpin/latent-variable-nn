{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Conv2D, MaxPooling2D, Reshape, Flatten, Input)\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow_probability.layers import DenseVariational\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/milesturpin/Dev/latent_variable_nn')\n",
    "sys.path.insert(1, '/Users/milesturpin/Dev/latent_variable_nn/models')\n",
    "\n",
    "from models.base_model import BaseModel\n",
    "from models.model_utils import (\n",
    "    latent_normal_vector, latent_vector_variational_posterior,\n",
    "    latent_normal_matrix, latent_matrix_variational_posterior, softplus_inverse)\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 'small'\n",
    "x_train = np.load('../data/femnist/{data_size}/x_train.npy'.format(data_size=data_size))\n",
    "y_train = np.load('../data/femnist/{data_size}/y_train.npy'.format(data_size=data_size))\n",
    "gid_train = np.load('../data/femnist/{data_size}/gid_train.npy'.format(data_size=data_size))\n",
    "x_test = np.load('../data/femnist/{data_size}/x_test.npy'.format(data_size=data_size))\n",
    "y_test = np.load('../data/femnist/{data_size}/y_test.npy'.format(data_size=data_size))\n",
    "gid_test = np.load('../data/femnist/{data_size}/gid_test.npy'.format(data_size=data_size))\n",
    "\n",
    "np.random.seed(335)\n",
    "from sklearn.utils import shuffle\n",
    "train_data = [x_train, gid_train, y_train]\n",
    "test_data = [x_test, gid_test, y_test]\n",
    "\n",
    "train_data = shuffle(*train_data, random_state=356)\n",
    "test_data = shuffle(*test_data, random_state=356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(Linear, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                             initializer='random_normal',\n",
    "                             trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                             initializer='random_normal',\n",
    "                             trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print(inputs.shape)\n",
    "        print(self.w.shape, self.b.shape)\n",
    "        print(tf.matmul(inputs, self.w).shape)\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Linear, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(784, 32) (32,)\n",
      "(10, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=432885, shape=(10, 32), dtype=float32, numpy=\n",
       "array([[-0.5440177 , -1.0042272 ,  1.1032884 , -0.10582794, -3.0298684 ,\n",
       "        -0.34431428, -0.98262805,  1.2245424 , -0.21390186, -0.98818064,\n",
       "         1.4837292 ,  0.6192355 , -0.40182206, -0.01606881,  2.4264178 ,\n",
       "         0.50637144,  1.4344455 , -0.7766889 , -1.3800389 ,  1.2437507 ,\n",
       "         1.9632759 ,  0.40609843, -1.5507433 , -1.3688016 ,  1.05972   ,\n",
       "         2.323223  ,  0.54351574, -1.194923  , -0.44533157, -0.23382336,\n",
       "         0.23519394, -1.0720731 ],\n",
       "       [-0.5440177 , -1.0042272 ,  1.1032884 , -0.10582794, -3.0298684 ,\n",
       "        -0.34431428, -0.98262805,  1.2245424 , -0.21390186, -0.98818064,\n",
       "         1.4837292 ,  0.6192355 , -0.40182206, -0.01606881,  2.4264178 ,\n",
       "         0.50637144,  1.4344455 , -0.7766889 , -1.3800389 ,  1.2437507 ,\n",
       "         1.9632759 ,  0.40609843, -1.5507433 , -1.3688016 ,  1.05972   ,\n",
       "         2.323223  ,  0.54351574, -1.194923  , -0.44533157, -0.23382336,\n",
       "         0.23519394, -1.0720731 ],\n",
       "       [-0.39465573, -0.86914176,  1.2735463 ,  0.14891322, -2.5674543 ,\n",
       "        -0.3931752 , -0.8525849 ,  1.270805  ,  0.10830604, -0.42306444,\n",
       "         1.8343725 ,  0.647454  , -0.88438606,  0.16797653,  2.6538842 ,\n",
       "         0.20330651,  1.2194022 , -0.7597764 , -1.2662129 ,  0.97292715,\n",
       "         2.0052886 ,  0.8627475 , -1.4791952 , -1.2663734 ,  1.1604141 ,\n",
       "         2.4214928 ,  0.41549632, -1.2418153 , -0.49326977, -0.43159032,\n",
       "        -0.09771616, -0.9819399 ],\n",
       "       [-0.16664746, -0.68907136,  1.659889  , -0.00392885, -2.7950296 ,\n",
       "        -0.4684154 , -0.70183796,  1.3815974 , -0.2991299 , -0.6604718 ,\n",
       "         1.6533893 ,  0.96639466, -0.76663816,  0.0232223 ,  2.1971114 ,\n",
       "         0.6939865 ,  1.3263583 , -0.49416488, -1.017631  ,  1.1889371 ,\n",
       "         2.0508778 ,  0.69539326, -1.7785213 , -1.4359562 ,  1.1139122 ,\n",
       "         2.7732263 ,  0.27842516, -1.322549  , -0.29113963, -0.41870785,\n",
       "         0.44412586, -1.0772969 ],\n",
       "       [-0.45847866, -0.81478053,  1.1935602 ,  0.123073  , -3.0539086 ,\n",
       "        -0.6352741 , -0.8445241 ,  1.4326075 , -0.24122997, -0.7169194 ,\n",
       "         1.6766346 ,  0.5804381 , -0.6696904 , -0.10711666,  2.446442  ,\n",
       "         0.8452916 ,  1.4163022 , -0.84176606, -1.2816553 ,  1.0633022 ,\n",
       "         1.8811492 ,  0.44633776, -1.7503089 , -1.3410279 ,  1.3001117 ,\n",
       "         2.8025668 ,  0.44051456, -1.4034525 , -0.28115648, -0.45353484,\n",
       "         0.02336731, -0.960687  ],\n",
       "       [-0.5229333 , -0.36786142,  1.8239902 ,  0.29108244, -2.9294732 ,\n",
       "        -0.34581968, -0.6631843 ,  1.3142114 , -0.13387975, -0.68739814,\n",
       "         1.5197998 ,  0.88543594, -0.91531587, -0.015417  ,  2.5094316 ,\n",
       "         0.5421091 ,  1.3338374 , -0.5326001 , -1.2826022 ,  1.3964386 ,\n",
       "         1.879343  ,  0.8702437 , -1.5037419 , -1.1786819 ,  1.5497097 ,\n",
       "         2.6311088 ,  0.39869618, -1.3704332 , -0.370745  , -0.5811766 ,\n",
       "        -0.07194275, -0.9448918 ],\n",
       "       [-0.19298741, -0.8351121 ,  1.8694401 ,  0.14782913, -3.003681  ,\n",
       "        -0.6327711 , -1.0865531 ,  0.94422954, -0.4929522 , -1.3658572 ,\n",
       "         1.3770092 ,  1.0447572 , -0.6958425 , -0.11623301,  2.4503047 ,\n",
       "         0.67004085,  1.5394223 , -0.6742126 , -1.2521935 ,  1.6313392 ,\n",
       "         1.865106  ,  0.61825204, -2.1689074 , -1.4332379 ,  1.0065836 ,\n",
       "         2.095472  ,  0.6190302 , -1.3107151 , -0.34689376, -0.27859044,\n",
       "         0.6421916 , -0.79086137],\n",
       "       [-0.36863813, -0.7858863 ,  1.1222633 , -0.11906035, -2.969144  ,\n",
       "        -0.46251747, -1.0011519 ,  1.2401528 , -0.16482729, -0.8717468 ,\n",
       "         1.3070927 ,  0.6509726 , -0.630401  ,  0.10256613,  2.53605   ,\n",
       "         0.61885273,  1.2895104 , -0.72958696, -1.2456012 ,  1.0211631 ,\n",
       "         1.8990593 ,  0.3919217 , -1.3329356 , -1.4442055 ,  1.3199569 ,\n",
       "         2.36047   ,  0.34327635, -1.0912731 , -0.15245697, -0.45911437,\n",
       "         0.2655302 , -1.2706407 ],\n",
       "       [-0.58458316, -0.6942249 ,  1.3934184 ,  0.28562117, -2.8809044 ,\n",
       "        -0.33596414, -0.8985465 ,  1.0943011 , -0.14904492, -0.64239   ,\n",
       "         1.8496985 ,  0.6762663 , -0.91024375, -0.11365976,  2.575277  ,\n",
       "         0.38070378,  1.4400107 , -0.7138945 , -1.5517316 ,  1.0001973 ,\n",
       "         2.0781462 ,  0.74161595, -1.5586554 , -1.3022891 ,  1.37776   ,\n",
       "         2.8042154 ,  0.20144436, -1.3154548 , -0.54847467, -0.25835562,\n",
       "        -0.1330561 , -0.90394384],\n",
       "       [-0.47994027, -0.73925227,  2.0594995 ,  0.20718558, -2.8598952 ,\n",
       "        -0.233575  , -0.9916633 ,  1.4460683 , -0.36920992, -0.63310623,\n",
       "         1.559887  ,  0.989427  , -0.95982265,  0.0069356 ,  2.133312  ,\n",
       "         0.7628502 ,  1.2258927 , -0.39594942, -1.0766836 ,  1.2581595 ,\n",
       "         1.9049072 ,  0.65249735, -1.6167252 , -1.3774055 ,  1.3324566 ,\n",
       "         2.4929538 ,  0.4562328 , -1.2211065 , -0.03556911, -0.73486763,\n",
       "         0.5062482 , -1.0984898 ]], dtype=float32)>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLP():\n",
    "    img = Input(shape=(784,))\n",
    "    x = Dense(units=512, activation='relu')(img)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    out = Dense(62, activation='softmax')(x)\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 62)                15934     \n",
      "=================================================================\n",
      "Total params: 549,182\n",
      "Trainable params: 549,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35535 samples, validate on 4044 samples\n",
      "Epoch 1/40\n",
      "35535/35535 [==============================] - 3s 73us/sample - loss: 3.0564 - acc: 0.2645 - val_loss: 2.3669 - val_acc: 0.4246\n",
      "Epoch 2/40\n",
      "35535/35535 [==============================] - 2s 64us/sample - loss: 1.9959 - acc: 0.4822 - val_loss: 1.7782 - val_acc: 0.5341\n",
      "Epoch 3/40\n",
      "35535/35535 [==============================] - 3s 75us/sample - loss: 1.7053 - acc: 0.5413 - val_loss: 1.6991 - val_acc: 0.5534\n",
      "Epoch 4/40\n",
      "35535/35535 [==============================] - 2s 63us/sample - loss: 1.5470 - acc: 0.5774 - val_loss: 1.5646 - val_acc: 0.5856\n",
      "Epoch 5/40\n",
      "35535/35535 [==============================] - 3s 79us/sample - loss: 1.4144 - acc: 0.6067 - val_loss: 1.4240 - val_acc: 0.6083\n",
      "Epoch 6/40\n",
      "35535/35535 [==============================] - 2s 63us/sample - loss: 1.3091 - acc: 0.6327 - val_loss: 1.2982 - val_acc: 0.6466\n",
      "Epoch 7/40\n",
      "35535/35535 [==============================] - 2s 70us/sample - loss: 1.2379 - acc: 0.6495 - val_loss: 1.2890 - val_acc: 0.6355\n",
      "Epoch 8/40\n",
      "35535/35535 [==============================] - 2s 59us/sample - loss: 1.1593 - acc: 0.6686 - val_loss: 1.1887 - val_acc: 0.6664\n",
      "Epoch 9/40\n",
      "35535/35535 [==============================] - 2s 66us/sample - loss: 1.1010 - acc: 0.6843 - val_loss: 1.1766 - val_acc: 0.6588\n",
      "Epoch 10/40\n",
      "35535/35535 [==============================] - 3s 78us/sample - loss: 1.0639 - acc: 0.6903 - val_loss: 1.0528 - val_acc: 0.6976\n",
      "Epoch 11/40\n",
      "35535/35535 [==============================] - 2s 65us/sample - loss: 1.0096 - acc: 0.7041 - val_loss: 1.0890 - val_acc: 0.6820\n",
      "Epoch 12/40\n",
      "35535/35535 [==============================] - 2s 68us/sample - loss: 0.9783 - acc: 0.7123 - val_loss: 1.0703 - val_acc: 0.6889\n",
      "Epoch 13/40\n",
      "35535/35535 [==============================] - 2s 64us/sample - loss: 0.9425 - acc: 0.7182 - val_loss: 1.0644 - val_acc: 0.6857\n",
      "Epoch 14/40\n",
      "35535/35535 [==============================] - 4s 116us/sample - loss: 0.9274 - acc: 0.7248 - val_loss: 1.0054 - val_acc: 0.7082\n",
      "Epoch 15/40\n",
      "35535/35535 [==============================] - 2s 68us/sample - loss: 0.8854 - acc: 0.7339 - val_loss: 0.9589 - val_acc: 0.7132\n",
      "Epoch 16/40\n",
      "35535/35535 [==============================] - 2s 64us/sample - loss: 0.8761 - acc: 0.7333 - val_loss: 0.9510 - val_acc: 0.7136\n",
      "Epoch 17/40\n",
      "35535/35535 [==============================] - 3s 76us/sample - loss: 0.8491 - acc: 0.7410 - val_loss: 0.9171 - val_acc: 0.7339\n",
      "Epoch 18/40\n",
      "35535/35535 [==============================] - 3s 73us/sample - loss: 0.8378 - acc: 0.7433 - val_loss: 0.9630 - val_acc: 0.7154\n",
      "Epoch 19/40\n",
      "35535/35535 [==============================] - 2s 69us/sample - loss: 0.8160 - acc: 0.7495 - val_loss: 0.9154 - val_acc: 0.7245\n",
      "Epoch 20/40\n",
      "35535/35535 [==============================] - 2s 63us/sample - loss: 0.8005 - acc: 0.7533 - val_loss: 0.8854 - val_acc: 0.7240\n",
      "Epoch 21/40\n",
      "35535/35535 [==============================] - 3s 81us/sample - loss: 0.7932 - acc: 0.7546 - val_loss: 0.9311 - val_acc: 0.7230\n",
      "Epoch 22/40\n",
      "35535/35535 [==============================] - 3s 70us/sample - loss: 0.7680 - acc: 0.7601 - val_loss: 0.8962 - val_acc: 0.7310\n",
      "Epoch 23/40\n",
      "35535/35535 [==============================] - 2s 68us/sample - loss: 0.7612 - acc: 0.7609 - val_loss: 0.8752 - val_acc: 0.7381\n",
      "Epoch 24/40\n",
      "35535/35535 [==============================] - 2s 64us/sample - loss: 0.7573 - acc: 0.7626 - val_loss: 0.8802 - val_acc: 0.7329\n",
      "Epoch 25/40\n",
      "35535/35535 [==============================] - 3s 70us/sample - loss: 0.7336 - acc: 0.7690 - val_loss: 0.8574 - val_acc: 0.7418\n",
      "Epoch 26/40\n",
      "35535/35535 [==============================] - 2s 69us/sample - loss: 0.7321 - acc: 0.7673 - val_loss: 0.8260 - val_acc: 0.7483\n",
      "Epoch 27/40\n",
      "35535/35535 [==============================] - 2s 64us/sample - loss: 0.7150 - acc: 0.7733 - val_loss: 0.8300 - val_acc: 0.7480\n",
      "Epoch 28/40\n",
      "35535/35535 [==============================] - 2s 67us/sample - loss: 0.7033 - acc: 0.7766 - val_loss: 0.8474 - val_acc: 0.7460\n",
      "Epoch 29/40\n",
      "35535/35535 [==============================] - 2s 62us/sample - loss: 0.6991 - acc: 0.7766 - val_loss: 0.8682 - val_acc: 0.7448\n",
      "Epoch 30/40\n",
      "35535/35535 [==============================] - 3s 78us/sample - loss: 0.6941 - acc: 0.7784 - val_loss: 0.9139 - val_acc: 0.7275\n",
      "Epoch 31/40\n",
      "35535/35535 [==============================] - 2s 66us/sample - loss: 0.6838 - acc: 0.7816 - val_loss: 0.8430 - val_acc: 0.7535\n",
      "Epoch 32/40\n",
      "35535/35535 [==============================] - 2s 69us/sample - loss: 0.6703 - acc: 0.7845 - val_loss: 0.8484 - val_acc: 0.7451\n",
      "Epoch 33/40\n",
      "35535/35535 [==============================] - 3s 89us/sample - loss: 0.6606 - acc: 0.7878 - val_loss: 0.8546 - val_acc: 0.7463\n",
      "Epoch 34/40\n",
      "35535/35535 [==============================] - 3s 79us/sample - loss: 0.6583 - acc: 0.7869 - val_loss: 0.7907 - val_acc: 0.7661\n",
      "Epoch 35/40\n",
      "35535/35535 [==============================] - 2s 70us/sample - loss: 0.6473 - acc: 0.7915 - val_loss: 0.7956 - val_acc: 0.7596\n",
      "Epoch 36/40\n",
      "35535/35535 [==============================] - 2s 63us/sample - loss: 0.6461 - acc: 0.7911 - val_loss: 0.8454 - val_acc: 0.7406\n",
      "Epoch 37/40\n",
      "35535/35535 [==============================] - 3s 81us/sample - loss: 0.6406 - acc: 0.7930 - val_loss: 0.8171 - val_acc: 0.7540\n",
      "Epoch 38/40\n",
      "35535/35535 [==============================] - 3s 80us/sample - loss: 0.6289 - acc: 0.7951 - val_loss: 0.8166 - val_acc: 0.7572\n",
      "Epoch 39/40\n",
      "35535/35535 [==============================] - 3s 82us/sample - loss: 0.6248 - acc: 0.7977 - val_loss: 0.7942 - val_acc: 0.7651\n",
      "Epoch 40/40\n",
      "35535/35535 [==============================] - 3s 81us/sample - loss: 0.6107 - acc: 0.7995 - val_loss: 0.7940 - val_acc: 0.7626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3c74d828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mlp = create_MLP()\n",
    "base_mlp.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "base_mlp.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "base_mlp.fit(x_train, y_train, batch_size=100, epochs=40,  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(784, 512), (512,), (512, 256), (256,), (256, 62), (62,)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in base_mlp.get_weights()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data_train = np.concatenate([x_train, to_categorical(gid_train)], axis=1)\n",
    "one_hot_data_test = np.concatenate([x_test, to_categorical(gid_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_MLP():\n",
    "    img = Input(shape=(784+190,))\n",
    "    x = Dense(units=512, activation='relu')(img)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    out = Dense(62, activation='softmax')(x)\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_model = create_one_hot_MLP()\n",
    "one_hot_model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "one_hot_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35535 samples, validate on 4044 samples\n",
      "Epoch 1/20\n",
      "35535/35535 [==============================] - 6s 170us/sample - loss: 0.6116 - acc: 0.8162 - val_loss: 0.7619 - val_acc: 0.7839\n",
      "Epoch 2/20\n",
      "35535/35535 [==============================] - 4s 100us/sample - loss: 0.5856 - acc: 0.8257 - val_loss: 0.8209 - val_acc: 0.7698\n",
      "Epoch 3/20\n",
      "35535/35535 [==============================] - 2s 62us/sample - loss: 0.5832 - acc: 0.8221 - val_loss: 0.7872 - val_acc: 0.7821\n",
      "Epoch 4/20\n",
      "35535/35535 [==============================] - 3s 77us/sample - loss: 0.5653 - acc: 0.8292 - val_loss: 0.7425 - val_acc: 0.7955\n",
      "Epoch 5/20\n",
      "35535/35535 [==============================] - 2s 63us/sample - loss: 0.5638 - acc: 0.8279 - val_loss: 0.7563 - val_acc: 0.7886\n",
      "Epoch 6/20\n",
      "35535/35535 [==============================] - 3s 75us/sample - loss: 0.5478 - acc: 0.8326 - val_loss: 0.8008 - val_acc: 0.7782\n",
      "Epoch 7/20\n",
      "35535/35535 [==============================] - 3s 84us/sample - loss: 0.5285 - acc: 0.8380 - val_loss: 0.8730 - val_acc: 0.7542\n",
      "Epoch 8/20\n",
      "35535/35535 [==============================] - 3s 88us/sample - loss: 0.5350 - acc: 0.8339 - val_loss: 0.7128 - val_acc: 0.8056\n",
      "Epoch 9/20\n",
      "35535/35535 [==============================] - 2s 69us/sample - loss: 0.5095 - acc: 0.8436 - val_loss: 0.7281 - val_acc: 0.8002\n",
      "Epoch 10/20\n",
      "35535/35535 [==============================] - 3s 83us/sample - loss: 0.4976 - acc: 0.8475 - val_loss: 0.7642 - val_acc: 0.7896\n",
      "Epoch 11/20\n",
      "35535/35535 [==============================] - 3s 96us/sample - loss: 0.4808 - acc: 0.8496 - val_loss: 0.7611 - val_acc: 0.7871\n",
      "Epoch 12/20\n",
      "35535/35535 [==============================] - 3s 89us/sample - loss: 0.4891 - acc: 0.8488 - val_loss: 0.7100 - val_acc: 0.8022\n",
      "Epoch 13/20\n",
      "35535/35535 [==============================] - 3s 73us/sample - loss: 0.4619 - acc: 0.8542 - val_loss: 0.7314 - val_acc: 0.7985\n",
      "Epoch 14/20\n",
      "35535/35535 [==============================] - 3s 77us/sample - loss: 0.4772 - acc: 0.8501 - val_loss: 0.7525 - val_acc: 0.7962\n",
      "Epoch 15/20\n",
      "35535/35535 [==============================] - 3s 83us/sample - loss: 0.4543 - acc: 0.8561 - val_loss: 0.7162 - val_acc: 0.8056\n",
      "Epoch 16/20\n",
      "35535/35535 [==============================] - 3s 80us/sample - loss: 0.4581 - acc: 0.8561 - val_loss: 0.7011 - val_acc: 0.8032\n",
      "Epoch 17/20\n",
      "35535/35535 [==============================] - 4s 111us/sample - loss: 0.4380 - acc: 0.8602 - val_loss: 0.7307 - val_acc: 0.8027\n",
      "Epoch 18/20\n",
      "35535/35535 [==============================] - 3s 98us/sample - loss: 0.4271 - acc: 0.8635 - val_loss: 0.8627 - val_acc: 0.7604\n",
      "Epoch 19/20\n",
      "35535/35535 [==============================] - 4s 99us/sample - loss: 0.4175 - acc: 0.8678 - val_loss: 0.7603 - val_acc: 0.7980\n",
      "Epoch 20/20\n",
      "35535/35535 [==============================] - 3s 81us/sample - loss: 0.4216 - acc: 0.8640 - val_loss: 0.7251 - val_acc: 0.8106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10b8f9860>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_model.fit(one_hot_data_train, y_train, batch_size=100, epochs=20, validation_data=(one_hot_data_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Multilevel MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelDense(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units, num_groups, multilevel_weights=True, multilevel_bias=True, activation=None, **kwargs):\n",
    "        super(MultilevelDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_groups = num_groups\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.multi_w = self.add_weight(shape=(self.num_groups, input_shape[-1], self.units), \n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.multi_b = self.add_weight(shape=(self.num_groups, self.units), \n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(MultilevelDense, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, gid):\n",
    "        #print(self.multi_w.shape, gid.shape)\n",
    "        w = tf.gather(self.multi_w, gid)\n",
    "        #w = tf.squeeze(w)\n",
    "        #print(w.shape)\n",
    "        b = tf.gather(self.multi_b, gid)\n",
    "        #b = tf.squeeze(b)\n",
    "        \n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        \n",
    "        #print(tf.matmul(x, w))\n",
    "        #print(w.shape,tf.transpose(w).shape,x.shape)\n",
    "        x = tf.matmul(w, x, transpose_a=True)\n",
    "        x = tf.squeeze(x)\n",
    "        #print(x,b)\n",
    "        out = self.activation(x + b)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(MultilevelDense, self).get_config()\n",
    "        config.update({'units': self.units, 'num_groups': self.num_groups})\n",
    "        return config\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldense = MultilevelDense(units=4, num_groups=190, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 4])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldense(x_train[:10], gid_train[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilevel_MLP(num_groups):\n",
    "    img = Input(shape=(784,))\n",
    "    gid = Input(shape=(1,), dtype=tf.int32)\n",
    "    x = Dense(units=512, activation='relu')(img)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #print(x)\n",
    "    out = MultilevelDense(62, num_groups=num_groups, activation='softmax')(x, gid)\n",
    "    model = Model(inputs=[img, gid], outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_84/Relu:0\", shape=(None, 256), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 2 and 1 for 'multilevel_dense_75/MatMul' (op: 'BatchMatMul') with input shapes: [?,1,256,62], [?,256,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 2 and 1 for 'multilevel_dense_75/MatMul' (op: 'BatchMatMul') with input shapes: [?,1,256,62], [?,256,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-e088cb8a545f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_multilevel_MLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m190\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-282-2573ea830d8e>\u001b[0m in \u001b[0;36mcreate_multilevel_MLP\u001b[0;34m(num_groups)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultilevelDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-bc645c717eed>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, gid)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(tf.matmul(x, w))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(w.shape,tf.transpose(w).shape,x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m       return gen_math_ops.batch_mat_mul(\n\u001b[0;32m-> 2542\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   2543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2544\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1515\u001b[0m   \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1517\u001b[0;31m         \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m   1518\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    798\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    799\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    801\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m    450\u001b[0m     return super(FuncGraph, self).create_op(\n\u001b[1;32m    451\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         compute_device=compute_device)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3477\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3480\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1981\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1982\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1983\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 2 and 1 for 'multilevel_dense_75/MatMul' (op: 'BatchMatMul') with input shapes: [?,1,256,62], [?,256,1]."
     ]
    }
   ],
   "source": [
    "ml_model = create_multilevel_MLP(num_groups=190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multilevel_mlp_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "multilevel_dense_70 (Multile multiple                  3027460   \n",
      "=================================================================\n",
      "Total params: 3,560,708\n",
      "Trainable params: 3,560,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_ = ml_model([x_train[:2], gid_train[:2]])\n",
    "ml_model.summary()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "ml_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from utils import robust_loss, round_nums\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Base model that serves as super class for different architectures.\n",
    "    Subclassed models are responsible for building out the latent space\n",
    "    as well as the model architecture. The base model contains training\n",
    "    loop code and utilities for saving results.\n",
    "\n",
    "    Args:\n",
    "        optimizer : keras optimizer object\n",
    "        loss_fn : keras loss function object\n",
    "        num_groups : array-like obj with number of unique groups in\n",
    "            each level of grouping; used to initialize latent variables\n",
    "        experiment_dir : used for saving training stats and model weights\n",
    "        logger : logging object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, loss_fn, train_size, num_groups, args):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model_size = args.model_size\n",
    "        self.z_dim = args.z_dim\n",
    "        self.train_size = train_size\n",
    "        self.num_groups = num_groups\n",
    "        self.seed = args.seed\n",
    "        self._build_model()\n",
    "        if args.latent_config != 'none':\n",
    "            self._build_latent_space()\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"Initialize model layers.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _build_latent_space(self):\n",
    "        \"\"\"Initialize latent variables and their prior distributions.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def create_batch_generator(\n",
    "        self, data, batch_size, prefetch=2):\n",
    "        \"\"\"Use tf.data API to create efficient input pipeline.\n",
    "\n",
    "        Should be overriden in the subclasses if particular dataset needs\n",
    "        a different batching procedure.\n",
    "\n",
    "        Args:\n",
    "            data : list of arrays of the form [x, gid, gid2, ..., y]\n",
    "            batch_size : self-explanatory\n",
    "            prefetch : number of batchs to precompute\n",
    "        \"\"\"\n",
    "        generator = tf.data.Dataset.from_tensor_slices(tuple(data))\n",
    "        generator = generator.batch(batch_size)\n",
    "        # Experimental feature, automatically picks # of batches to process\n",
    "        generator = generator.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return generator\n",
    "\n",
    "\n",
    "    def train(self, train_data, test_data, batch_size, num_epochs, eval_every=1, print_freq=10):\n",
    "        \"\"\"Train network.\n",
    "\n",
    "        Args:\n",
    "            train_data, test_data : list of numpy arrays in the order\n",
    "                [x, gid, gid2, ..., y]\n",
    "            batch_size : self-explanatory\n",
    "            num_epochs : self-explanatory\n",
    "            eval_every : number of epochs in between test set evaluations\n",
    "            print_freq : how many times per epoch to print training\n",
    "                progress. Useful when individual epochs take a long time\n",
    "        \"\"\"\n",
    "        #self.logger.info('Evaluating untrained model...')\n",
    "        #self.log_group_test_performance(test_data, epoch=0)\n",
    "\n",
    "        # TODO: find less hacky way to build model, get summary\n",
    "        inputs, labels = train_data[:-1], train_data[-1]\n",
    "        inputs = [x[:5] for x in inputs]\n",
    "        outputs = self(*inputs)\n",
    "        # Try to print summary of param counts, won't work for some models\n",
    "        try:\n",
    "            self.summary(print_fn=print)\n",
    "        except:\n",
    "            print('Configuration not amenable to `summary`.')\n",
    "\n",
    "        # Stateful Keras object for keeping track of mean loss\n",
    "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
    "\n",
    "        last_time = time.time()\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            print('--- Epoch {} ---'.format(epoch))\n",
    "\n",
    "            train_generator = self.create_batch_generator(train_data, batch_size)\n",
    "\n",
    "            for step, batch in enumerate(train_generator):\n",
    "                loss = self.train_step(batch)\n",
    "                train_loss(loss)\n",
    "\n",
    "                # Print out train loss every 1/print_freq thru train set\n",
    "                num_batches = np.ceil(len(train_data[0])/batch_size)\n",
    "                if (step+1) % np.ceil(num_batches/print_freq) == 0 or (step+1) == num_batches:\n",
    "                    print(\n",
    "                        'Step {} - train loss: {:.5f}, time elapsed: {:d}s'.format(\n",
    "                            step+1, train_loss.result().numpy(),\n",
    "                            round(time.time()-last_time)))\n",
    "\n",
    "                    last_time = time.time()\n",
    "                    train_loss.reset_states()\n",
    "\n",
    "            if epoch % eval_every == 0 or epoch == num_epochs:\n",
    "                print('Evaluating test set...')\n",
    "                self.log_group_test_performance(test_data, epoch=epoch)\n",
    "                #self.save_weights()\n",
    "\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"\n",
    "        Idiomatic Tensorflow for making predictions and computing\n",
    "        gradients.\n",
    "        \"\"\"\n",
    "        inputs, labels = batch[:-1], batch[-1]\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self(*inputs)\n",
    "            loss = self.loss_fn(labels, pred)\n",
    "            # Only need to add KL loss once per epoch\n",
    "            #print((sum(self.losses) / self.train_size))\n",
    "            loss += sum(self.losses) / self.train_size\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def log_group_test_performance(self, test_data, epoch):\n",
    "        \"\"\"Evaluate test set performance across groups.\n",
    "\n",
    "        Args:\n",
    "            test_data : list of test arrays\n",
    "            epoch : current epoch, used for logging results\n",
    "        \"\"\"\n",
    "\n",
    "        # Don't shuffle so that we can match up batch preds with input data\n",
    "        test_generator = self.create_batch_generator(\n",
    "            test_data, batch_size=1000)\n",
    "\n",
    "        scores = []\n",
    "        # tqdm prints nice progress bars\n",
    "        for test_batch in tqdm(test_generator):\n",
    "            inputs, labels = test_batch[:-1], test_batch[-1]\n",
    "            score = self(*inputs)\n",
    "            scores.append(score)\n",
    "        scores = np.concatenate(scores)\n",
    "        preds = scores.argmax(axis=1)\n",
    "\n",
    "#         output_file = os.path.join(self.experiment_dir,\n",
    "#             'training_stats{}.csv'.format(epoch))\n",
    "#         file = open(output_file, 'w')\n",
    "\n",
    "#         # Header for CSV file, add more columns if add metrics in get_metrics\n",
    "#         file.write('epoch,gid,test_acc,test_f1,test_loss\\n')\n",
    "\n",
    "        # Get stats with respect to first level grouping\n",
    "        # i.e. whatever group level is in second index\n",
    "        gid_test = test_data[1]\n",
    "        y_test = test_data[-1]\n",
    "        results_list = []\n",
    "        for gid in trange(self.num_groups[0]):\n",
    "            # Get instances of each group, calculate performance\n",
    "            gid_idx = np.where(gid_test == gid)[0]\n",
    "            gid_metrics = self.get_metrics(y_test[gid_idx], scores[gid_idx])\n",
    "            results_list.append(gid_metrics)\n",
    "            # Write out line to csv e.g. `3,347,0.87,0.86,0.34`\n",
    "            \n",
    "            #file.write(','.join(map(str, [epoch, gid] + gid_metrics)) + '\\n')\n",
    "        #file.close()\n",
    "\n",
    "        results_arr = np.stack(results_list)\n",
    "        group_acc = results_arr[:,0]\n",
    "        stats = round_nums(\n",
    "            accuracy_score(y_test, preds),\n",
    "            np.percentile(sorted(group_acc), 10),\n",
    "            np.percentile(sorted(group_acc), 90))\n",
    "\n",
    "        # TODO: add more metrics\n",
    "        print(\n",
    "            'Test accuracy: {:.5f}, 10th percentile: {:.5f}, 90th percentile: {:.5f}'.format(*stats))\n",
    "\n",
    "\n",
    "    # TODO: add more metrics, if add more need to add to CSV header\n",
    "    def get_metrics(self, y_true, y_score):\n",
    "        y_pred = tf.math.argmax(y_score, axis=1)\n",
    "        return [\n",
    "            accuracy_score(y_true, y_pred),\n",
    "            f1_score(y_true, y_pred, average='weighted'),\n",
    "            robust_loss(y_true, y_score),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelMLP(BaseModel):\n",
    "    \n",
    "    def __init__(self, optimizer, loss_fn, train_size, num_groups, args):\n",
    "        super(MultilevelMLP, self).__init__(optimizer, loss_fn, train_size, num_groups, args)\n",
    "        \n",
    "    def _build_model(self):\n",
    "        self.dense1 = Dense(units=512, activation='relu')\n",
    "        self.dense2 = Dense(units=256, activation='relu')\n",
    "        self.ml_dense = MultilevelDense(62, num_groups=self.num_groups, activation='softmax')\n",
    "        \n",
    "    def _build_latent_space(self):\n",
    "        pass\n",
    "        \n",
    "    def call(self, x, gid):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.ml_dense(x, gid)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args_dict = vars(args)\n",
    "args_dict.update({\n",
    "    \"batch_size\": 100,\n",
    "    \"data_dir\": \"data\",\n",
    "    \"data_size\": \"small\",\n",
    "    \"dataset\": \"femnist\",\n",
    "    \"description\": \"lr sched 50, bigger batch more epochs\",\n",
    "    \"eval_every\": 1,\n",
    "    \"latent_config\": \"factor2\",\n",
    "    \"lr\": 0.001,\n",
    "    \"model_size\": \"small\",\n",
    "    \"num_epochs\": 40,\n",
    "    \"print_freq\": 1,\n",
    "    \"seed\": 1227,\n",
    "    \"testing\": True,\n",
    "    \"z_dim\": [\n",
    "        62\n",
    "    ]\n",
    "})\n",
    "ml_model = MultilevelMLP(opt, loss_fn, 35535, 190, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multilevel_mlp_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "multilevel_dense_80 (Multile multiple                  3027460   \n",
      "=================================================================\n",
      "Total params: 3,560,708\n",
      "Trainable params: 3,560,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "--- Epoch 1 ---\n",
      "Step 36 - train loss: 4.13192, time elapsed: 6s\n",
      "Step 72 - train loss: 4.11971, time elapsed: 5s\n",
      "Step 108 - train loss: 4.10985, time elapsed: 5s\n",
      "Step 144 - train loss: 4.08328, time elapsed: 5s\n",
      "Step 180 - train loss: 4.11244, time elapsed: 5s\n",
      "Step 216 - train loss: 4.09985, time elapsed: 4s\n",
      "Step 252 - train loss: 4.11612, time elapsed: 5s\n",
      "Step 288 - train loss: 4.10679, time elapsed: 5s\n",
      "Step 324 - train loss: 4.11698, time elapsed: 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 356 - train loss: 4.12769, time elapsed: 4s\n",
      "Evaluating test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 18.28it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-324-bc3e50385115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-302-ef03a3aec9c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, test_data, batch_size, num_epochs, eval_every, print_freq)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluating test set...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_group_test_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;31m#self.save_weights()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-302-ef03a3aec9c3>\u001b[0m in \u001b[0;36mlog_group_test_performance\u001b[0;34m(self, test_data, epoch)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mgid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;31m# Get instances of each group, calculate performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mgid_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgid_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ml_model.train([x_train, gid_train, y_train], [x_test, gid_test, y_test], batch_size=100, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.06748185  0.03969476 -0.03092025  0.01272973  0.03301796 -0.03741422\n",
      "   0.02798387 -0.04484198 -0.02708249 -0.01406365  0.03128406  0.0530345\n",
      "  -0.02823323  0.09702478  0.04532017 -0.00336938  0.01084191 -0.03770605\n",
      "   0.01827123  0.00543186 -0.06078134  0.02129716 -0.11266416  0.0059648\n",
      "   0.04361    -0.06416956 -0.07238913  0.0104103  -0.09759513 -0.06082897\n",
      "  -0.0091065  -0.06174833 -0.02937673 -0.05784327 -0.04405056 -0.00570857\n",
      "   0.07046047  0.03697755 -0.00273403 -0.00322475 -0.0751567   0.02579825\n",
      "   0.00590726  0.03809592 -0.0004933   0.08686652 -0.06789909 -0.00627298\n",
      "  -0.01915285  0.00255602 -0.07464639 -0.01323446  0.01534919 -0.0244153\n",
      "   0.04534295 -0.00083769 -0.08018332  0.092474    0.0629398  -0.08053047\n",
      "  -0.0419539  -0.01578863]\n",
      " [-0.06748185  0.03969476 -0.03092025  0.01272973  0.03301796 -0.03741422\n",
      "   0.02798387 -0.04484198 -0.02708249 -0.01406365  0.03128406  0.0530345\n",
      "  -0.02823323  0.09702478  0.04532017 -0.00336938  0.01084191 -0.03770605\n",
      "   0.01827123  0.00543186 -0.06078134  0.02129716 -0.11266416  0.0059648\n",
      "   0.04361    -0.06416956 -0.07238913  0.0104103  -0.09759513 -0.06082897\n",
      "  -0.0091065  -0.06174833 -0.02937673 -0.05784327 -0.04405056 -0.00570857\n",
      "   0.07046047  0.03697755 -0.00273403 -0.00322475 -0.0751567   0.02579825\n",
      "   0.00590726  0.03809592 -0.0004933   0.08686652 -0.06789909 -0.00627298\n",
      "  -0.01915285  0.00255602 -0.07464639 -0.01323446  0.01534919 -0.0244153\n",
      "   0.04534295 -0.00083769 -0.08018332  0.092474    0.0629398  -0.08053047\n",
      "  -0.0419539  -0.01578863]], shape=(2, 62), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 62), dtype=float32)\n",
      "Model: \"multilevel_mlp_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             multiple                  131328    \n",
      "_________________________________________________________________\n",
      "multilevel_dense_76 (Multile multiple                  3027460   \n",
      "=================================================================\n",
      "Total params: 3,560,708\n",
      "Trainable params: 3,560,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_ = ml_model([x_train[:2], gid_train[:2]])\n",
    "ml_model.summary()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "### I THINK I JUST CANT USE COMPILE OR FIT\n",
    "ml_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"multilevel_dense_76/Squeeze:0\", dtype=float32) Tensor(\"multilevel_dense_76/Identity_1:0\", shape=(None, 62), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-c4101e0e44e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2501\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2504\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2773\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m           \u001b[0;31m# Reset to the previously saved value. If `call()` had `add_metric`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m           \u001b[0;31m# or `add_loss`, then `_contains_symbolic_tensors` will have been set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-286-7b70fbcd762e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-bc645c717eed>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, gid)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "ml_model.fit([x_train, gid_train], y_train, batch_size=100, epochs=20, validation_data=([x_test, gid_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
